{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前回の演習に関してはモジュール化したスクリプトの説明でカバー出来ているのでそちらを参照**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前回のおさらい\n",
    "\n",
    "分類モデルpart1では、ロジスティック回帰を使って2値分類を紹介した。基本的に流れはあの通りである。つまり、\n",
    "\n",
    "- 前処理・特徴量エンジニアリング：データの読み込みや加工、スケーリングやOne Hot、訓練用・評価用に分割を含む\n",
    "\n",
    "- 学習\n",
    "\n",
    "- 評価\n",
    "\n",
    "のサイクルをひたすら回す必要がある。この中で一番労力を割くのが**前処理**部分である。実際の業務では今回利用しているオープンデータやKaggleデータセットとは異なり、自分でデータを色々なDBから引っ張ってきて結合して作る必要がある。ちなみに機械学習エンジニアとしてある会社のプロジェクトにアサインされたのに、集約された全社的なデータ分析基盤が存在せず、色々な部署に頭を下げてデータを集めてくるという炎上プロジェクトに組み込まれてた人がいました・・・（結局コードほとんど書かなかったそう）。なのでデータ分析基盤が存在しない会社だとデータ読み込み・加工まで持っていくのがかなりの労力かかる案件はまだまだありそうです。\n",
    "\n",
    "次に大変なのが全トレーニングデータを訓練用・評価用に分割する、という作業。学習したモデルがちゃんと未知のデータに対してもちゃんと予測できるか確かめるために評価用データを作るが、この評価用データでの精度がまた他の未知のデータに対しても同じくらいになるように構築しないと意味がない。part1で紹介したようなstratifyで目的変数の分布を揃えるようなことは基本。あと説明変数の分布？というのも訓練・評価・テストで揃えるというのも大事。この辺はデータを泥臭く観察したりドメイン知識使ったりする必要があり、かなり大変。例えばある特徴量の傾向が訓練時とテスト時で変化する（例えば何かのキャンペーンがあったとか）ケースなど。最近はDataRobotなど機械学習の自動化ツールなどがあるけどこの辺の問題が解決しないと使うのはなかなか難しい。逆に言うと機械学習に関わる人の価値はこの辺の手腕にかかっていると言える（仕事で機械学習に携われるか否かの分水嶺かも）。ちなみに現在Kaggleで世界ランク1位のbestfittingさんは去年のインタビューでこんなこといってましたので参考までに。\n",
    "\n",
    "> *A good CV is half of success. I won’t go to the next step if I can’t find a good way to evaluate my model.*  <br><br> （意訳）: *自分のモデルに対する良い評価方法が見つかればコンペには半分勝ったようなもんだ。逆に良い評価方法が得られない時点では次のステップ（多分特徴量作ったりモデル変えたりとか）にはいかないよ。*\n",
    "\n",
    "※CV = Cross Validationのこと。次に説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "前回はモデルの評価用データセットを作るとき、全トレーニングデータを8:2で分割していた。これをホールドアウト法と呼ぶ。しかし、評価用に切り出した全トレーニングデータの２割は学習に使われないことになる。実際に予測したい未知のテストデータを予測する上で大事な特徴は学習部分（８割の方）ではなく、むしろ評価用（２割の方）により含まれていたとしたら勿体無い。そこでよりロバストな評価をするために使うのがCross Validationである。\n",
    "\n",
    "![cv](./cv.png)\n",
    "\n",
    "青が学習部分、オレンジ色が評価部分のデータセットを表す。このように全トレーニングデータをk個に分割し（上の例ではk=5）、k個それぞれが評価されるようにするのが**k-fold Cross Validation**という方法である。上の例は5-fold Cross Validationである。難点としては8:2に分けたホールドアウトの学習よりも5foldは5倍学習時間がかかることである。scikit-learnには各fold内で学習、評価間で目的変数の隔たりを無くすように分割する**StratifiedKFold**があったりする。基本的にはこれを使うが、問題によっては特定のカラムの情報が学習、評価間で被らないように分割する**GroupKFold**などを使うこともある。ちなみに広告業界ではCVではなく、時系列スプリットしたホールドアウトを使うことが多い印象。それはユーザーの行動には時系列性があるのでちゃんと過去のデータで学習してそれよりも未来のデータで精度が出るかが大事であるため（厳密にはユーザーの行動だけでなく、広告代理店の運用方法も時系列性がある。広告月予算の消化ペースによって運用スタイル変えてきたり）。\n",
    "\n",
    "余談：機械学習は各サンプルがi.i.d.（独立同分布）から生成されているという仮定の上に成り立っているものが多い（もちろん時系列分析とかは違う）。言い換えるとあるデータが生成されたことが他のデータの生成プロセスに影響を受けないということであるが、現実のデータは必ずしもそうなっていない。当然このi.i.dの仮定からよりずれるほど機械学習の相性が悪くなる。訓練時のデータが生成される確率分布とテスト時の分布がずれると手元の評価値は良いが実プロダクトに組み込んだ途端、事故レベルで精度が下がるというケースを見てきました。この辺は本や論文が参考にならない世界なので実務経験を積むしかないのが辛いところ。ちなみにweb系のサービスに限定されるがKDD（やWWW、WSDMあたりも）という会議では各会社の事例が細かく論文になって出ていたりするので、勝ちパターンを探ることも出来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation実践\n",
    "\n",
    "じゃあ実際にCVをやってみましょう。特に断らない限り、StratifiedKFoldを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "PATH = './'\n",
    "df = pd.read_csv(os.path.join(PATH, 'application_train.csv'), nrows=None)\n",
    "X = df[[col for col in df.columns if col not in ['TARGET']]]\n",
    "y = df.TARGET\n",
    "\n",
    "folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=2019)\n",
    "\n",
    "#分割したデータのindexを返す\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    print('{0}fold'.format(n_fold))\n",
    "    print('TRAIN', train_idx)\n",
    "    print('VALID', valid_idx)\n",
    "    print(X.iloc[train_idx].shape) #dfはindex指定で読み込むときilocを使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation特徴量生成のテクニック\n",
    "\n",
    "agg系の特徴量、つまりあるカテゴリ変数（これは２つ以上あっても良い）毎にある数値変数のavg、max、minなどを取った特徴量も有効であるケースが多い。これはPandas研修でやったようにgroupbyとaggの組み合わせで出来る。しかし、１つのagg系特徴量を作る毎にgroupby、aggなど書いていたらコード量が膨大になり、またコード上の管理も困難となる。そこで、１例としてagg系特徴量の生成コードを紹介する。\n",
    "\n",
    "どのカテゴリ変数でgroupbyして、それに対してどの数値変数で集約するのかを記述した設定コードをまず定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_settings = [\n",
    "   (['CODE_GENDER', 'NAME_EDUCATION_TYPE'], \n",
    "                            [('EXT_SOURCE_1', 'mean'), ('EXT_SOURCE_2', 'max')]\n",
    "   ),\n",
    "    \n",
    "    (['CODE_GENDER'], \n",
    "                            [('AMT_INCOME_TOTAL', 'std')]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_aggregate_names = []\n",
    "for groupby_cols, specs in aggregation_settings:\n",
    "    group_object = df.groupby(groupby_cols)\n",
    "    for select, agg in specs:\n",
    "        groupby_aggregate_name = '{}_{}_{}'.format('_'.join(groupby_cols), agg, select)\n",
    "        df = df.merge(group_object[select]\n",
    "                             .agg(agg)\n",
    "                             .reset_index()\n",
    "                             .rename(index=str,\n",
    "                                     columns={select: groupby_aggregate_name})\n",
    "                             [groupby_cols + [groupby_aggregate_name]],\n",
    "                             on=groupby_cols,\n",
    "                             how='left')\n",
    "        groupby_aggregate_names.append(groupby_aggregate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四則演算系の特徴量\n",
    "\n",
    "ある２つの特徴量の四則演算を計算したものを追加すると精度が上がることがある。Home Creditコンペで顕著だったのは比率を計算する特徴量だろう。\n",
    "\n",
    "```python\n",
    "そのローンの応募者が人生の全期間のうち、現在の仕事に従事している割合\n",
    "実質、今の会社の会社員歴のようなものでローンの審査では重要そう（ローン組んだことないのでわかりませんが）\n",
    "df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "\n",
    "ローンで買おうとしている商品価格？と申請した借金額の比\n",
    "df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "```\n",
    "\n",
    "多くの機械学習アルゴリズムではこのような関係（特に掛け算、割り算系）を自動抽出することは苦手なのであらかじめ自分で作る必要がある。この辺りはモデル作成者がドメイン知識を総動員して頑張るところ。\n",
    "\n",
    "## 実運用を見据えて\n",
    "\n",
    "**これはとても重要な話だが何故か本などに書いてあるのを見たことがない**\n",
    "\n",
    "Kaggleやデータ分析コンペ慣れている人がやりがちなのがデータの前処理や変換をtrainとtest結合してやってしまうことである。ただ、実際にはtestデータは学習時に手に入らないことが多い。つまり商用に組み込むモデルを作成する場合はtrainのみでデータ処理部分を記述できなければ意味がない。\n",
    "\n",
    "今回私が皆さんに配ったスクリプト群のpreprocess.pyではtrainとtestを結合して処理してしまっている。**この処理をtrainにだけ（つまりapplication_preprocessingにtrainだけ食わせる）適応するように変更した場合、具体的にどういった困難さが生じるか考えてみて下さい。そしてそれを回避するためにはどのような処理にすると良いでしょうか？**\n",
    "\n",
    "※まだ教えてないことを使う必要があるので、実装する必要はありません。演習2が重いですし、そこまで時間使わないでいいです。\n",
    "\n",
    "### 解答？多分色々なやり方あります\n",
    "\n",
    "例えばカテゴリ変数のエンコーディングが顕著に影響があると思います。例えばtrainに対してone hotをpandasのget_dummiesにしたとしましょう。すると各カテゴリ数とそれに対応する水準数分だけ次元が増えます。trainのone hot後にカテゴリ変数の次元が100になったとしましょう。じゃあ未知のデータtestを同様に処理するにはどうしましょう？？trainにしか存在しないカテゴリ（都道府県カラムだったら北海道はtrainにはあるがtestにはないとか）があると次元数が変わってしまいます。するとモデルがtestデータを入力した時点でエラー吐いてしまいます。これを回避するためにカテゴリ変数の処理なら次のライブラリを入れると楽です。\n",
    "\n",
    "http://contrib.scikit-learn.org/categorical-encoding/index.html\n",
    "\n",
    "もし今後業務でPySparkを使うことがあれば**Pipeline**をfitした後にsaveすることで回避できると思います（Sparkはversionによる変化が激しいのでその都度ドキュメントみて下さい・・・）。scikit-learnにもPipelineが存在するので、あとで紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青森</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>宮崎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  都道府県\n",
       "0  北海道\n",
       "1   青森\n",
       "2   宮崎\n",
       "3   秋田\n",
       "4  北海道\n",
       "5   秋田\n",
       "6  北海道"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使い方\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "#前々回くらいの都道府県カテゴリ\n",
    "pref_train = pd.DataFrame({'都道府県':['北海道', '青森', '宮崎', '秋田', '北海道', '秋田', '北海道']})\n",
    "pref_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_ohe = ce.OneHotEncoder(cols=['都道府県'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県_1</th>\n",
       "      <th>都道府県_2</th>\n",
       "      <th>都道府県_3</th>\n",
       "      <th>都道府県_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   都道府県_1  都道府県_2  都道府県_3  都道府県_4\n",
       "0       1       0       0       0\n",
       "1       0       1       0       0\n",
       "2       0       0       1       0\n",
       "3       0       0       0       1\n",
       "4       1       0       0       0\n",
       "5       0       0       0       1\n",
       "6       1       0       0       0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_ohe.fit_transform(pref_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>宮崎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  都道府県\n",
       "0   宮崎\n",
       "1   秋田\n",
       "2  北海道\n",
       "3   秋田\n",
       "4  北海道"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_test = pd.DataFrame({'都道府県':['宮崎', '秋田', '北海道', '秋田', '北海道']})\n",
    "pref_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県_1</th>\n",
       "      <th>都道府県_2</th>\n",
       "      <th>都道府県_3</th>\n",
       "      <th>都道府県_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   都道府県_1  都道府県_2  都道府県_3  都道府県_4\n",
       "0       0       0       1       0\n",
       "1       0       0       0       1\n",
       "2       1       0       0       0\n",
       "3       0       0       0       1\n",
       "4       1       0       0       0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_ohe.transform(pref_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainには青森があるが、testにはないケース。\n",
    "\n",
    "厄介なのはtrainにはないが、testに新たに出現するケース。ここではtestに愛媛を追加してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>愛媛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  都道府県\n",
       "0   愛媛\n",
       "1   秋田\n",
       "2  北海道\n",
       "3   秋田\n",
       "4  北海道"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_test = pd.DataFrame({'都道府県':['愛媛', '秋田', '北海道', '秋田', '北海道']})\n",
    "pref_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>都道府県_1</th>\n",
       "      <th>都道府県_2</th>\n",
       "      <th>都道府県_3</th>\n",
       "      <th>都道府県_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   都道府県_1  都道府県_2  都道府県_3  都道府県_4\n",
       "0       0       0       0       0\n",
       "1       0       0       0       1\n",
       "2       1       0       0       0\n",
       "3       0       0       0       1\n",
       "4       1       0       0       0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_ohe.transform(pref_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すると愛媛に対応する１行目は全てゼロになり、One Hot的には期待通りの挙動。\n",
    "\n",
    "scikit-learnや今回のライブラリはfit, tranform, fit_transformというメソッドが存在する。イメージとしてはfitは学習、tranformは予測、fit_transformはどちらも一気に行う、という感じで覚えておくと良い。なので、まずはtrain時にはfit_transformをtrainデータに対して行い、その時のオブジェクト（今回の例ならce_ohe）をpickleで保存。そしてtest時にはそのオブジェクトをloadし、testデータに対してtransformすれば良い。\n",
    "\n",
    "ちなみにカテゴリ変数が頻繁に更新されるケースがある場合はOne Hotは避けた方が良い。上のようにほとんど全てのカラムがゼロになってしまい、情報が落ちてしまうので。そのような場合は **Feature Hashing**という手法など検討しましょう。Feature Hashingに関してはFeature Engineeringの本で紹介されています。直近のKaggleコンペで使われた例としてはTalking dataコンペでしょうか。上位陣は使っていませんでしたがKernelでは使用例があるので参考になるかもしれません。ただこのコンペはデータ数が2億くらいあるので注意\n",
    "\n",
    "ではあるカテゴリにはLabelEncodingをし、その他のカテゴリにはOneHotEncodingをして、数値データにはStandardScalerを使い、などと処理が多岐に渡った場合はそれぞれをpickleで保存するべきでしょうか？？それだけdumpしたモジュールが増えると商用だとそれらのファイルを管理するのも大変になります。なので処理群をPipelineで保存すると１つにまとめられるので楽です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>人口</th>\n",
       "      <th>都道府県</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>青森</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>宮崎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    人口 都道府県\n",
       "0  201  北海道\n",
       "1  123   青森\n",
       "2   33   宮崎\n",
       "3   21   秋田\n",
       "4  201  北海道\n",
       "5   21   秋田\n",
       "6  201  北海道"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_train_2 = pd.DataFrame(\n",
    "    {'都道府県':['北海道', '青森', '宮崎', '秋田', '北海道', '秋田', '北海道'],\n",
    "    '人口':['201', '123', '33', '21', '201', '21', '201']\n",
    "    }\n",
    ")\n",
    "pref_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_features = ['人口']\n",
    "categorical_features = ['都道府県']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.10500171,  0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [-0.99751621,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [-1.1445186 ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-1.1445186 ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(pref_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(preprocessor, open('prep.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_preprocessor = pickle.load(open('prep.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>人口</th>\n",
       "      <th>都道府県</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>沖縄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>宮崎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>秋田</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201</td>\n",
       "      <td>北海道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    人口 都道府県\n",
       "0  201  北海道\n",
       "1   10   沖縄\n",
       "2   33   宮崎\n",
       "3   21   秋田\n",
       "4  201  北海道\n",
       "5   21   秋田\n",
       "6  201  北海道"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_test_2 = pd.DataFrame(\n",
    "    {'都道府県':['北海道', '沖縄',  '宮崎', '秋田', '北海道', '秋田', '北海道'],\n",
    "    '人口':['201','10', '33', '21', '201', '21', '201']\n",
    "    }\n",
    ")\n",
    "pref_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-1.27927079,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.99751621,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [-1.1445186 ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-1.1445186 ,  0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 1.06051723,  1.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_preprocessor.transform(pref_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自作したクラスをPipelineに追加することも可能です。その際にはsklearn.baseのBaseEstimator, TransformerMixinというクラスを継承して作って下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習1\n",
    "\n",
    "今回の研修でCVを紹介しました。今までtrain_test_splitだった箇所をStratifiedKFoldに変更して5foldで平均AUCを計算してみて下さい。それが出来たら次に**kfold ensemble**という手法を実装して下さい。これはkfoldによってモデルを5個作ってそれぞれの予測結果を平均するという方法です。イメージとしてはk=5なら\n",
    "\n",
    "$$\n",
    "(pred1+pred2+pred3+pred4+pred5)/5\n",
    "$$\n",
    "\n",
    "という単純な操作です。これをtestデータに対して実行し、ホールドアウト法で学習・予測してsubmitした結果と比べてどちらがAUCが向上するか確かめてみて下さい。\n",
    "\n",
    "### 解答\n",
    "\n",
    "まず前回のpreprocess.pyで生成した前処理済みpickleファイルを再利用しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import pickle\n",
    "import os, sys\n",
    "import datetime\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "sys.path.append('./src/') #モジュールが入っているディレクトリのパスを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from utils import setup_logger, ModelFactory\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-31 16:36:52,701 - INFO - logger set up\n"
     ]
    }
   ],
   "source": [
    "NOW = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "logger = setup_logger('./src/logs/train_{0}.log'.format(NOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-01 05:33:23,494 - INFO - Selecting model => LogisticRegression\n",
      "2019-06-01 05:34:52,641 - INFO - Fold 1 AUC:0.7415\n",
      "2019-06-01 05:34:52,897 - INFO - Selecting model => LogisticRegression\n",
      "2019-06-01 05:36:27,239 - INFO - Fold 2 AUC:0.7442\n",
      "2019-06-01 05:36:27,491 - INFO - Selecting model => LogisticRegression\n",
      "2019-06-01 05:37:39,906 - INFO - Fold 3 AUC:0.7404\n",
      "2019-06-01 05:37:40,170 - INFO - Selecting model => LogisticRegression\n",
      "2019-06-01 05:38:44,583 - INFO - Fold 4 AUC:0.7425\n",
      "2019-06-01 05:38:44,840 - INFO - Selecting model => LogisticRegression\n",
      "2019-06-01 05:39:51,570 - INFO - Fold 5 AUC:0.7424\n",
      "2019-06-01 05:39:51,618 - INFO - AUC: 0.7422±0.0012\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_pickle('./src/output/application_train.pickle')\n",
    "test_df = pd.read_pickle('./src/output/application_test.pickle')\n",
    "X = train_df[[col for col in train_df.columns if col not in config.unused]]\n",
    "y = train_df.TARGET\n",
    "test = test_df[[col for col in df.columns if col not in config.unused]]\n",
    "\n",
    "folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=2019)\n",
    "\n",
    "full_auc = []\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model = ModelFactory(config.MODEL_NAME, config.MODEL_CONFIG, logger)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, pred)\n",
    "    \n",
    "    logger.info('Fold {0} AUC:{1:.4f}'.format(n_fold + 1, auc_score))\n",
    "    full_auc.append(auc_score)\n",
    "    \n",
    "    #predict test data\n",
    "    test_preds += model.predict(test)[:, 1]/folds.n_splits\n",
    "    \n",
    "logger.info('AUC: {0:.4f}±{1:.4f}'.format(np.mean(full_auc), np.std(full_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'SK_ID_CURR': submission.SK_ID_CURR , 'TARGET': test_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習2\n",
    "\n",
    "では実際に特徴量エンジニアリング、特徴量選択、train_test_split→CVに変更などを実際に試してみて、最低でも10パターンの実験を行って下さい。その際にbaselineは私の配布したスクリプト（スケーリング無のもの）として、それに加える形で行って下さい。\n",
    "\n",
    "どのような実験をしたか、を管理するのはどのツール使っても構いません。エクセルでも良いし、TrelloでもJIRAでもいいです。gitのコミットメッセージは使いにくいかも。\n",
    "\n",
    "※今回もLogisticRegression縛りで。スケーリング無にするにはconfig.pyのSCALING = Falseにしてください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
